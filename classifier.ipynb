{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12687\n",
      "12687\n"
     ]
    }
   ],
   "source": [
    "with open('dev.json') as fp:\n",
    "    stereoSet = json.load(fp)[\"data\"]\n",
    "\n",
    "all_example = []\n",
    "all_label = []\n",
    "\n",
    "\n",
    "inter_set = stereoSet[\"intersentence\"]\n",
    "for set_exmaple in inter_set:\n",
    "    context = set_exmaple[\"context\"]\n",
    "    sentences = set_exmaple[\"sentences\"]\n",
    "    for sen in sentences:\n",
    "        all_example.append(context + \" \" + sen[\"sentence\"])\n",
    "        if sen[\"gold_label\"] == \"unrelated\":\n",
    "            all_label.append(0)\n",
    "        if sen[\"gold_label\"] == \"stereotype\":\n",
    "            all_label.append(1)\n",
    "        if sen[\"gold_label\"] == \"anti-stereotype\":\n",
    "            all_label.append(2)\n",
    "\n",
    "\n",
    "intra_set = stereoSet[\"intrasentence\"]\n",
    "\n",
    "for set_exmaple in intra_set:\n",
    "    context = set_exmaple[\"context\"]\n",
    "    sentences = set_exmaple[\"sentences\"]\n",
    "    for sen in sentences:\n",
    "        all_example.append(context + \" \" + sen[\"sentence\"])\n",
    "        if sen[\"gold_label\"] == \"unrelated\":\n",
    "            all_label.append(0)\n",
    "        if sen[\"gold_label\"] == \"stereotype\":\n",
    "            all_label.append(1)\n",
    "        if sen[\"gold_label\"] == \"anti-stereotype\":\n",
    "            all_label.append(2)\n",
    "\n",
    "\n",
    "print(len(all_example))\n",
    "print(len(all_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\ProgramFiles\\anaconda3\\envs\\eecs487_project\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "class StereoDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len     \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(all_example)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_split = int(len(indices) * 0.7)\n",
    "val_split = int(len(indices) * 0.15)\n",
    "\n",
    "train_idx = indices[:train_split]\n",
    "val_idx = indices[train_split : train_split+val_split]\n",
    "test_idx = indices[train_split+val_split : ]\n",
    "\n",
    "\n",
    "train_sentences = [all_example[i] for i in train_idx]\n",
    "train_labels = [all_label[i] for i in train_idx]\n",
    "val_sentences = [all_example[i] for i in val_idx]\n",
    "val_labels = [all_label[i] for i in val_idx]\n",
    "test_sentences = [all_example[i] for i in test_idx]\n",
    "test_labels = [all_label[i] for i in test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = StereoDataset(train_sentences, train_labels, tokenizer, 32)\n",
    "val_dataset = StereoDataset(val_sentences, val_labels, tokenizer, 32)\n",
    "test_dataset = StereoDataset(test_sentences, test_labels, tokenizer, 32)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, num_out):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_out)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        logits = self.classifier(cls_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_out = 3\n",
    "model = BertClassifier(num_out)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "model.to(device)\n",
    "loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 555/555 [00:21<00:00, 26.20it/s]\n",
      "100%|██████████| 119/119 [00:01<00:00, 74.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1, Train Loss:  0.049, Train Accuracy:  0.607, Val Loss:  0.038, Val Accuracy:  0.698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 555/555 [00:21<00:00, 25.99it/s]\n",
      "100%|██████████| 119/119 [00:01<00:00, 73.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2, Train Loss:  0.033, Train Accuracy:  0.756, Val Loss:  0.036, Val Accuracy:  0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 555/555 [00:21<00:00, 25.33it/s]\n",
      "100%|██████████| 119/119 [00:01<00:00, 76.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3, Train Loss:  0.027, Train Accuracy:  0.805, Val Loss:  0.036, Val Accuracy:  0.733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 555/555 [00:21<00:00, 25.60it/s]\n",
      "100%|██████████| 119/119 [00:01<00:00, 72.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4, Train Loss:  0.022, Train Accuracy:  0.845, Val Loss:  0.037, Val Accuracy:  0.738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 555/555 [00:21<00:00, 25.94it/s]\n",
      "100%|██████████| 119/119 [00:01<00:00, 74.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5, Train Loss:  0.018, Train Accuracy:  0.873, Val Loss:  0.038, Val Accuracy:  0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "\n",
    "    for inputs in tqdm(train_loader):\n",
    "        input_ids = inputs[\"input_ids\"].to(device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "        labels = inputs[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_ids, attention_mask)\n",
    "        loss = loss_fn(output, labels)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc += (output.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    total_dev_loss = 0\n",
    "    total_dev_acc = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for inputs in tqdm(val_loader):\n",
    "            input_ids = inputs[\"input_ids\"].to(device)\n",
    "            attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "            labels = inputs[\"label\"].to(device)\n",
    "\n",
    "            output = model(input_ids, attention_mask)\n",
    "            loss = loss_fn(output, labels)\n",
    "\n",
    "            total_dev_loss += loss.item()\n",
    "            total_dev_acc += (output.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "    print(f'Epochs: {epoch + 1}, Train Loss: {total_loss / len(train_dataset): .3f}, Train Accuracy: {total_acc / len(train_dataset): .3f}, Val Loss: {total_dev_loss / len(val_dataset): .3f}, Val Accuracy: {total_dev_acc / len(val_dataset): .3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:01<00:00, 74.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_test_acc = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs in tqdm(test_loader):\n",
    "        input_ids = inputs[\"input_ids\"].to(device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "        labels = inputs[\"label\"].to(device)\n",
    "\n",
    "        output = model(input_ids, attention_mask)\n",
    "        \n",
    "        total_test_acc += (output.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {total_test_acc / len(test_dataset): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_path = []\n",
    "dir = './BASIL/annotations/'\n",
    "for folder in os.listdir(dir):\n",
    "    folder_path = os.path.join(dir, folder)\n",
    "    for filename in os.listdir(folder_path):\n",
    "      annotations_path.append(os.path.join(folder_path, filename))\n",
    "\n",
    "\n",
    "articles_path = []\n",
    "dir = './BASIL/articles/'\n",
    "for folder in os.listdir(dir):\n",
    "    folder_path = os.path.join(dir, folder)\n",
    "    for filename in os.listdir(folder_path):\n",
    "      articles_path.append(os.path.join(folder_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./BASIL/annotations/2010\\\\2b95d2cf-e979-4f9c-ae27-9a5370934f23_1_ann.json', './BASIL/annotations/2010\\\\2b95d2cf-e979-4f9c-ae27-9a5370934f23_2_ann.json', './BASIL/annotations/2010\\\\2b95d2cf-e979-4f9c-ae27-9a5370934f23_3_ann.json', './BASIL/annotations/2010\\\\38f7cbb7-5d6a-4c89-bcbd-8e164144172a_1_ann.json', './BASIL/annotations/2010\\\\38f7cbb7-5d6a-4c89-bcbd-8e164144172a_2_ann.json', './BASIL/annotations/2010\\\\38f7cbb7-5d6a-4c89-bcbd-8e164144172a_3_ann.json', './BASIL/annotations/2010\\\\45bd61bc-c356-4450-9e3a-cbfc862b09fd_1_ann.json', './BASIL/annotations/2010\\\\45bd61bc-c356-4450-9e3a-cbfc862b09fd_2_ann.json', './BASIL/annotations/2010\\\\45bd61bc-c356-4450-9e3a-cbfc862b09fd_3_ann.json', './BASIL/annotations/2010\\\\6b541575-99b1-40d2-8730-9bb868ee38ed_1_ann.json', './BASIL/annotations/2010\\\\6b541575-99b1-40d2-8730-9bb868ee38ed_2_ann.json', './BASIL/annotations/2010\\\\6b541575-99b1-40d2-8730-9bb868ee38ed_3_ann.json', './BASIL/annotations/2010\\\\6f95dcb9-e960-45ac-8c0e-91b85724c909_1_ann.json', './BASIL/annotations/2010\\\\6f95dcb9-e960-45ac-8c0e-91b85724c909_2_ann.json', './BASIL/annotations/2010\\\\6f95dcb9-e960-45ac-8c0e-91b85724c909_3_ann.json', './BASIL/annotations/2010\\\\74708dbf-5dfc-4c66-8419-d7dbc00e4a06_1_ann.json', './BASIL/annotations/2010\\\\74708dbf-5dfc-4c66-8419-d7dbc00e4a06_2_ann.json', './BASIL/annotations/2010\\\\74708dbf-5dfc-4c66-8419-d7dbc00e4a06_3_ann.json', './BASIL/annotations/2010\\\\85475456-f38e-4c30-895d-ca2c819c6af1_1_ann.json', './BASIL/annotations/2010\\\\85475456-f38e-4c30-895d-ca2c819c6af1_2_ann.json', './BASIL/annotations/2010\\\\85475456-f38e-4c30-895d-ca2c819c6af1_3_ann.json', './BASIL/annotations/2010\\\\97b1305c-13ca-4b74-a56a-f459bd79dfaf_1_ann.json', './BASIL/annotations/2010\\\\97b1305c-13ca-4b74-a56a-f459bd79dfaf_2_ann.json', './BASIL/annotations/2010\\\\97b1305c-13ca-4b74-a56a-f459bd79dfaf_3_ann.json', './BASIL/annotations/2010\\\\ae243a95-b2c2-410c-9e2b-b083b4b8eb48_1_ann.json', './BASIL/annotations/2010\\\\ae243a95-b2c2-410c-9e2b-b083b4b8eb48_2_ann.json', './BASIL/annotations/2010\\\\ae243a95-b2c2-410c-9e2b-b083b4b8eb48_3_ann.json', './BASIL/annotations/2010\\\\df5fe55a-dfcb-4817-8631-830f47c21a72_1_ann.json', './BASIL/annotations/2010\\\\df5fe55a-dfcb-4817-8631-830f47c21a72_2_ann.json', './BASIL/annotations/2010\\\\df5fe55a-dfcb-4817-8631-830f47c21a72_3_ann.json', './BASIL/annotations/2011\\\\005a2961-0c2e-4575-8eec-770ba52a08e0_1_ann.json', './BASIL/annotations/2011\\\\005a2961-0c2e-4575-8eec-770ba52a08e0_2_ann.json', './BASIL/annotations/2011\\\\005a2961-0c2e-4575-8eec-770ba52a08e0_3_ann.json', './BASIL/annotations/2011\\\\0ffb34cd-c367-4d90-aca7-7fcac3ed8f3d_1_ann.json', './BASIL/annotations/2011\\\\0ffb34cd-c367-4d90-aca7-7fcac3ed8f3d_2_ann.json', './BASIL/annotations/2011\\\\0ffb34cd-c367-4d90-aca7-7fcac3ed8f3d_3_ann.json', './BASIL/annotations/2011\\\\2058ec60-5372-4f5f-83a3-da780be3a350_1_ann.json', './BASIL/annotations/2011\\\\2058ec60-5372-4f5f-83a3-da780be3a350_2_ann.json', './BASIL/annotations/2011\\\\2058ec60-5372-4f5f-83a3-da780be3a350_3_ann.json', './BASIL/annotations/2011\\\\2153fb3e-6b09-410c-bfea-d095c49a54ba_1_ann.json', './BASIL/annotations/2011\\\\2153fb3e-6b09-410c-bfea-d095c49a54ba_2_ann.json', './BASIL/annotations/2011\\\\2153fb3e-6b09-410c-bfea-d095c49a54ba_3_ann.json', './BASIL/annotations/2011\\\\3db93526-a344-4ea4-8772-3734d0cfdfb1_1_ann.json', './BASIL/annotations/2011\\\\3db93526-a344-4ea4-8772-3734d0cfdfb1_2_ann.json', './BASIL/annotations/2011\\\\3db93526-a344-4ea4-8772-3734d0cfdfb1_3_ann.json', './BASIL/annotations/2011\\\\550b80db-bdd5-442b-8f70-c8e9f3203a13_1_ann.json', './BASIL/annotations/2011\\\\550b80db-bdd5-442b-8f70-c8e9f3203a13_2_ann.json', './BASIL/annotations/2011\\\\550b80db-bdd5-442b-8f70-c8e9f3203a13_3_ann.json', './BASIL/annotations/2011\\\\576116e5-2b18-4d35-be73-36f5863c9468_1_ann.json', './BASIL/annotations/2011\\\\576116e5-2b18-4d35-be73-36f5863c9468_2_ann.json', './BASIL/annotations/2011\\\\576116e5-2b18-4d35-be73-36f5863c9468_3_ann.json', './BASIL/annotations/2011\\\\97566c74-e000-49fb-b091-e6ec6e179de0_1_ann.json', './BASIL/annotations/2011\\\\97566c74-e000-49fb-b091-e6ec6e179de0_2_ann.json', './BASIL/annotations/2011\\\\97566c74-e000-49fb-b091-e6ec6e179de0_3_ann.json', './BASIL/annotations/2011\\\\a28a0329-0887-42dc-bd3d-3bb4f8926757_1_ann.json', './BASIL/annotations/2011\\\\a28a0329-0887-42dc-bd3d-3bb4f8926757_2_ann.json', './BASIL/annotations/2011\\\\a28a0329-0887-42dc-bd3d-3bb4f8926757_3_ann.json', './BASIL/annotations/2011\\\\c21cb217-3e2c-49bd-884d-5c74a165ef10_1_ann.json', './BASIL/annotations/2011\\\\c21cb217-3e2c-49bd-884d-5c74a165ef10_2_ann.json', './BASIL/annotations/2011\\\\c21cb217-3e2c-49bd-884d-5c74a165ef10_3_ann.json', './BASIL/annotations/2012\\\\08bb9bee-c167-4c17-9c6d-4a1259231eb7_1_ann.json', './BASIL/annotations/2012\\\\08bb9bee-c167-4c17-9c6d-4a1259231eb7_2_ann.json', './BASIL/annotations/2012\\\\08bb9bee-c167-4c17-9c6d-4a1259231eb7_3_ann.json', './BASIL/annotations/2012\\\\29ffd053-7684-469b-a600-97000579bd01_1_ann.json', './BASIL/annotations/2012\\\\29ffd053-7684-469b-a600-97000579bd01_2_ann.json', './BASIL/annotations/2012\\\\29ffd053-7684-469b-a600-97000579bd01_3_ann.json', './BASIL/annotations/2012\\\\2ec04201-2016-4227-baf7-ba8289058203_1_ann.json', './BASIL/annotations/2012\\\\2ec04201-2016-4227-baf7-ba8289058203_2_ann.json', './BASIL/annotations/2012\\\\2ec04201-2016-4227-baf7-ba8289058203_3_ann.json', './BASIL/annotations/2012\\\\450755dd-30d3-478b-933e-917be5c384ba_1_ann.json', './BASIL/annotations/2012\\\\450755dd-30d3-478b-933e-917be5c384ba_2_ann.json', './BASIL/annotations/2012\\\\450755dd-30d3-478b-933e-917be5c384ba_3_ann.json', './BASIL/annotations/2012\\\\65cb14cb-2d27-41e5-a2be-6fd6314f4363_1_ann.json', './BASIL/annotations/2012\\\\65cb14cb-2d27-41e5-a2be-6fd6314f4363_2_ann.json', './BASIL/annotations/2012\\\\65cb14cb-2d27-41e5-a2be-6fd6314f4363_3_ann.json', './BASIL/annotations/2012\\\\8dc7ccfe-5cf0-482f-9101-a7c69881da4d_1_ann.json', './BASIL/annotations/2012\\\\8dc7ccfe-5cf0-482f-9101-a7c69881da4d_2_ann.json', './BASIL/annotations/2012\\\\8dc7ccfe-5cf0-482f-9101-a7c69881da4d_3_ann.json', './BASIL/annotations/2012\\\\b4dbeda7-a1f3-4711-ae77-db23809d1ed2_1_ann.json', './BASIL/annotations/2012\\\\b4dbeda7-a1f3-4711-ae77-db23809d1ed2_2_ann.json', './BASIL/annotations/2012\\\\b4dbeda7-a1f3-4711-ae77-db23809d1ed2_3_ann.json', './BASIL/annotations/2012\\\\b5eefefb-2a33-45de-abe1-f855c94165f4_1_ann.json', './BASIL/annotations/2012\\\\b5eefefb-2a33-45de-abe1-f855c94165f4_2_ann.json', './BASIL/annotations/2012\\\\b5eefefb-2a33-45de-abe1-f855c94165f4_3_ann.json', './BASIL/annotations/2012\\\\cad4bba5-cf97-45cb-8059-ebeb47dcec7a_1_ann.json', './BASIL/annotations/2012\\\\cad4bba5-cf97-45cb-8059-ebeb47dcec7a_2_ann.json', './BASIL/annotations/2012\\\\cad4bba5-cf97-45cb-8059-ebeb47dcec7a_3_ann.json', './BASIL/annotations/2012\\\\f11c2566-848a-4e29-b8c5-4de0a81114e4_1_ann.json', './BASIL/annotations/2012\\\\f11c2566-848a-4e29-b8c5-4de0a81114e4_2_ann.json', './BASIL/annotations/2012\\\\f11c2566-848a-4e29-b8c5-4de0a81114e4_3_ann.json', './BASIL/annotations/2013\\\\11c9f251-35c8-4452-b052-df9be61464c6_1_ann.json', './BASIL/annotations/2013\\\\11c9f251-35c8-4452-b052-df9be61464c6_2_ann.json', './BASIL/annotations/2013\\\\11c9f251-35c8-4452-b052-df9be61464c6_3_ann.json', './BASIL/annotations/2013\\\\1bb79cc1-5d69-4136-a23d-6dbd300cbf25_1_ann.json', './BASIL/annotations/2013\\\\1bb79cc1-5d69-4136-a23d-6dbd300cbf25_2_ann.json', './BASIL/annotations/2013\\\\1bb79cc1-5d69-4136-a23d-6dbd300cbf25_3_ann.json', './BASIL/annotations/2013\\\\526cabb7-02a3-4adb-8e90-ec781c40c498_1_ann.json', './BASIL/annotations/2013\\\\526cabb7-02a3-4adb-8e90-ec781c40c498_2_ann.json', './BASIL/annotations/2013\\\\526cabb7-02a3-4adb-8e90-ec781c40c498_3_ann.json', './BASIL/annotations/2013\\\\68748e7f-cf6e-4ac7-8504-454c0876880d_1_ann.json', './BASIL/annotations/2013\\\\68748e7f-cf6e-4ac7-8504-454c0876880d_2_ann.json', './BASIL/annotations/2013\\\\68748e7f-cf6e-4ac7-8504-454c0876880d_3_ann.json', './BASIL/annotations/2013\\\\70c744ad-e950-445c-8a7a-0782b0a7d20b_1_ann.json', './BASIL/annotations/2013\\\\70c744ad-e950-445c-8a7a-0782b0a7d20b_2_ann.json', './BASIL/annotations/2013\\\\70c744ad-e950-445c-8a7a-0782b0a7d20b_3_ann.json', './BASIL/annotations/2013\\\\84678e18-0b79-4570-9c9f-cb1cf88d968e_1_ann.json', './BASIL/annotations/2013\\\\84678e18-0b79-4570-9c9f-cb1cf88d968e_2_ann.json', './BASIL/annotations/2013\\\\84678e18-0b79-4570-9c9f-cb1cf88d968e_3_ann.json', './BASIL/annotations/2013\\\\9879bbc0-eab3-482f-bf6b-a4b519393986_1_ann.json', './BASIL/annotations/2013\\\\9879bbc0-eab3-482f-bf6b-a4b519393986_2_ann.json', './BASIL/annotations/2013\\\\9879bbc0-eab3-482f-bf6b-a4b519393986_3_ann.json', './BASIL/annotations/2013\\\\a4f1d515-d7d9-4319-b2e0-4d56e9d45554_1_ann.json', './BASIL/annotations/2013\\\\a4f1d515-d7d9-4319-b2e0-4d56e9d45554_2_ann.json', './BASIL/annotations/2013\\\\a4f1d515-d7d9-4319-b2e0-4d56e9d45554_3_ann.json', './BASIL/annotations/2013\\\\d3a1ce0a-fc48-4827-a278-8f0ce8c7a519_1_ann.json', './BASIL/annotations/2013\\\\d3a1ce0a-fc48-4827-a278-8f0ce8c7a519_2_ann.json', './BASIL/annotations/2013\\\\d3a1ce0a-fc48-4827-a278-8f0ce8c7a519_3_ann.json', './BASIL/annotations/2013\\\\f506aafc-8b43-427a-936e-bbd1ef33e076_1_ann.json', './BASIL/annotations/2013\\\\f506aafc-8b43-427a-936e-bbd1ef33e076_2_ann.json', './BASIL/annotations/2013\\\\f506aafc-8b43-427a-936e-bbd1ef33e076_3_ann.json', './BASIL/annotations/2014\\\\22b6e900-4826-4b09-a9f8-5d7afe46e78b_1_ann.json', './BASIL/annotations/2014\\\\22b6e900-4826-4b09-a9f8-5d7afe46e78b_2_ann.json', './BASIL/annotations/2014\\\\22b6e900-4826-4b09-a9f8-5d7afe46e78b_3_ann.json', './BASIL/annotations/2014\\\\33521e65-12da-4521-b132-7b606243b0e4_1_ann.json', './BASIL/annotations/2014\\\\33521e65-12da-4521-b132-7b606243b0e4_2_ann.json', './BASIL/annotations/2014\\\\33521e65-12da-4521-b132-7b606243b0e4_3_ann.json', './BASIL/annotations/2014\\\\58ed2376-35a0-453a-a08e-5cd87e3bdea5_1_ann.json', './BASIL/annotations/2014\\\\58ed2376-35a0-453a-a08e-5cd87e3bdea5_2_ann.json', './BASIL/annotations/2014\\\\58ed2376-35a0-453a-a08e-5cd87e3bdea5_3_ann.json', './BASIL/annotations/2014\\\\96b7046f-f584-422f-a626-6f86a26dfd8b_1_ann.json', './BASIL/annotations/2014\\\\96b7046f-f584-422f-a626-6f86a26dfd8b_2_ann.json', './BASIL/annotations/2014\\\\96b7046f-f584-422f-a626-6f86a26dfd8b_3_ann.json', './BASIL/annotations/2014\\\\b764f81f-6d08-4d7c-b1a8-8961bed0a455_1_ann.json', './BASIL/annotations/2014\\\\b764f81f-6d08-4d7c-b1a8-8961bed0a455_2_ann.json', './BASIL/annotations/2014\\\\b764f81f-6d08-4d7c-b1a8-8961bed0a455_3_ann.json', './BASIL/annotations/2014\\\\c99adbdd-eaf3-4844-9548-2642e80de4e2_1_ann.json', './BASIL/annotations/2014\\\\c99adbdd-eaf3-4844-9548-2642e80de4e2_2_ann.json', './BASIL/annotations/2014\\\\c99adbdd-eaf3-4844-9548-2642e80de4e2_3_ann.json', './BASIL/annotations/2014\\\\ccf19ab6-7878-4378-b99c-2b08cc21371f_1_ann.json', './BASIL/annotations/2014\\\\ccf19ab6-7878-4378-b99c-2b08cc21371f_2_ann.json', './BASIL/annotations/2014\\\\ccf19ab6-7878-4378-b99c-2b08cc21371f_3_ann.json', './BASIL/annotations/2014\\\\d1344998-0e7c-409e-aaad-df5be687fc94_1_ann.json', './BASIL/annotations/2014\\\\d1344998-0e7c-409e-aaad-df5be687fc94_2_ann.json', './BASIL/annotations/2014\\\\d1344998-0e7c-409e-aaad-df5be687fc94_3_ann.json', './BASIL/annotations/2014\\\\ed8c136f-8d44-4c83-ad05-0dcfc3a0c54a_1_ann.json', './BASIL/annotations/2014\\\\ed8c136f-8d44-4c83-ad05-0dcfc3a0c54a_2_ann.json', './BASIL/annotations/2014\\\\ed8c136f-8d44-4c83-ad05-0dcfc3a0c54a_3_ann.json', './BASIL/annotations/2014\\\\ee05c9b3-529c-4268-ad72-19bd34f7197e_1_ann.json', './BASIL/annotations/2014\\\\ee05c9b3-529c-4268-ad72-19bd34f7197e_2_ann.json', './BASIL/annotations/2014\\\\ee05c9b3-529c-4268-ad72-19bd34f7197e_3_ann.json', './BASIL/annotations/2015\\\\13792511-5142-449f-8d3e-d77d790f65ec_1_ann.json', './BASIL/annotations/2015\\\\13792511-5142-449f-8d3e-d77d790f65ec_2_ann.json', './BASIL/annotations/2015\\\\13792511-5142-449f-8d3e-d77d790f65ec_3_ann.json', './BASIL/annotations/2015\\\\2742e9c1-2943-496f-8b23-faf5332e1612_1_ann.json', './BASIL/annotations/2015\\\\2742e9c1-2943-496f-8b23-faf5332e1612_2_ann.json', './BASIL/annotations/2015\\\\2742e9c1-2943-496f-8b23-faf5332e1612_3_ann.json', './BASIL/annotations/2015\\\\2b9468af-4ab0-4f25-85f4-c3ef93d72006_1_ann.json', './BASIL/annotations/2015\\\\2b9468af-4ab0-4f25-85f4-c3ef93d72006_2_ann.json', './BASIL/annotations/2015\\\\2b9468af-4ab0-4f25-85f4-c3ef93d72006_3_ann.json', './BASIL/annotations/2015\\\\4f473faf-f928-4cfd-8bed-00578be9db9a_1_ann.json', './BASIL/annotations/2015\\\\4f473faf-f928-4cfd-8bed-00578be9db9a_2_ann.json', './BASIL/annotations/2015\\\\4f473faf-f928-4cfd-8bed-00578be9db9a_3_ann.json', './BASIL/annotations/2015\\\\6e502405-bc90-4416-a787-3122918aa648_1_ann.json', './BASIL/annotations/2015\\\\6e502405-bc90-4416-a787-3122918aa648_2_ann.json', './BASIL/annotations/2015\\\\6e502405-bc90-4416-a787-3122918aa648_3_ann.json', './BASIL/annotations/2015\\\\7f9c83f7-3efa-4c7a-adef-3ebdeda96042_1_ann.json', './BASIL/annotations/2015\\\\7f9c83f7-3efa-4c7a-adef-3ebdeda96042_2_ann.json', './BASIL/annotations/2015\\\\7f9c83f7-3efa-4c7a-adef-3ebdeda96042_3_ann.json', './BASIL/annotations/2015\\\\8dac6c12-b5ca-468c-a249-7e0ab42f6b52_1_ann.json', './BASIL/annotations/2015\\\\8dac6c12-b5ca-468c-a249-7e0ab42f6b52_2_ann.json', './BASIL/annotations/2015\\\\8dac6c12-b5ca-468c-a249-7e0ab42f6b52_3_ann.json', './BASIL/annotations/2015\\\\a4edca3f-931f-4785-8c3f-f3d8fa84cbec_1_ann.json', './BASIL/annotations/2015\\\\a4edca3f-931f-4785-8c3f-f3d8fa84cbec_2_ann.json', './BASIL/annotations/2015\\\\a4edca3f-931f-4785-8c3f-f3d8fa84cbec_3_ann.json', './BASIL/annotations/2015\\\\af4a3f41-eeb5-49fa-a276-e97c230b25f0_1_ann.json', './BASIL/annotations/2015\\\\af4a3f41-eeb5-49fa-a276-e97c230b25f0_2_ann.json', './BASIL/annotations/2015\\\\af4a3f41-eeb5-49fa-a276-e97c230b25f0_3_ann.json', './BASIL/annotations/2015\\\\c5534b7e-a373-4962-8345-3847bc41a636_1_ann.json', './BASIL/annotations/2015\\\\c5534b7e-a373-4962-8345-3847bc41a636_2_ann.json', './BASIL/annotations/2015\\\\c5534b7e-a373-4962-8345-3847bc41a636_3_ann.json', './BASIL/annotations/2016\\\\1b96a5db-8974-46d3-82d7-5dfef02f650e_1_ann.json', './BASIL/annotations/2016\\\\1b96a5db-8974-46d3-82d7-5dfef02f650e_2_ann.json', './BASIL/annotations/2016\\\\1b96a5db-8974-46d3-82d7-5dfef02f650e_3_ann.json', './BASIL/annotations/2016\\\\472158a1-4e39-4214-8397-904e66f2b4c5_1_ann.json', './BASIL/annotations/2016\\\\472158a1-4e39-4214-8397-904e66f2b4c5_2_ann.json', './BASIL/annotations/2016\\\\472158a1-4e39-4214-8397-904e66f2b4c5_3_ann.json', './BASIL/annotations/2016\\\\59f2f47c-5da0-4fbc-be6e-4f15d45d82e2_1_ann.json', './BASIL/annotations/2016\\\\59f2f47c-5da0-4fbc-be6e-4f15d45d82e2_2_ann.json', './BASIL/annotations/2016\\\\59f2f47c-5da0-4fbc-be6e-4f15d45d82e2_3_ann.json', './BASIL/annotations/2016\\\\76810849-0335-4ad3-9eaf-f0d9c5baceb6_1_ann.json', './BASIL/annotations/2016\\\\76810849-0335-4ad3-9eaf-f0d9c5baceb6_2_ann.json', './BASIL/annotations/2016\\\\76810849-0335-4ad3-9eaf-f0d9c5baceb6_3_ann.json', './BASIL/annotations/2016\\\\79bf99c6-6fca-4ce4-8ae1-8771de026142_1_ann.json', './BASIL/annotations/2016\\\\79bf99c6-6fca-4ce4-8ae1-8771de026142_2_ann.json', './BASIL/annotations/2016\\\\79bf99c6-6fca-4ce4-8ae1-8771de026142_3_ann.json', './BASIL/annotations/2016\\\\7a97de89-1433-46f7-bcc2-f80b041cb9a0_1_ann.json', './BASIL/annotations/2016\\\\7a97de89-1433-46f7-bcc2-f80b041cb9a0_2_ann.json', './BASIL/annotations/2016\\\\7a97de89-1433-46f7-bcc2-f80b041cb9a0_3_ann.json', './BASIL/annotations/2016\\\\8385a996-1afc-4778-a06d-7070a8f19e27_1_ann.json', './BASIL/annotations/2016\\\\8385a996-1afc-4778-a06d-7070a8f19e27_2_ann.json', './BASIL/annotations/2016\\\\8385a996-1afc-4778-a06d-7070a8f19e27_3_ann.json', './BASIL/annotations/2016\\\\8abec8d9-50a2-480e-969a-157f94954f4d_1_ann.json', './BASIL/annotations/2016\\\\8abec8d9-50a2-480e-969a-157f94954f4d_2_ann.json', './BASIL/annotations/2016\\\\8abec8d9-50a2-480e-969a-157f94954f4d_3_ann.json', './BASIL/annotations/2016\\\\d4a4bc34-e48b-4485-86b2-f1daf4d464dd_1_ann.json', './BASIL/annotations/2016\\\\d4a4bc34-e48b-4485-86b2-f1daf4d464dd_2_ann.json', './BASIL/annotations/2016\\\\d4a4bc34-e48b-4485-86b2-f1daf4d464dd_3_ann.json', './BASIL/annotations/2016\\\\eadabee7-3db9-43c4-a485-3e8b1882cd3c_1_ann.json', './BASIL/annotations/2016\\\\eadabee7-3db9-43c4-a485-3e8b1882cd3c_2_ann.json', './BASIL/annotations/2016\\\\eadabee7-3db9-43c4-a485-3e8b1882cd3c_3_ann.json', './BASIL/annotations/2017\\\\0c78e748-efbf-417c-a8c1-beeb6480147f_1_ann.json', './BASIL/annotations/2017\\\\0c78e748-efbf-417c-a8c1-beeb6480147f_2_ann.json', './BASIL/annotations/2017\\\\0c78e748-efbf-417c-a8c1-beeb6480147f_3_ann.json', './BASIL/annotations/2017\\\\47a209b0-fc26-4a0a-a1fe-e4310d1d2419_1_ann.json', './BASIL/annotations/2017\\\\47a209b0-fc26-4a0a-a1fe-e4310d1d2419_2_ann.json', './BASIL/annotations/2017\\\\47a209b0-fc26-4a0a-a1fe-e4310d1d2419_3_ann.json', './BASIL/annotations/2017\\\\542cd22c-ea80-4669-995b-6ac6a33823f7_1_ann.json', './BASIL/annotations/2017\\\\542cd22c-ea80-4669-995b-6ac6a33823f7_2_ann.json', './BASIL/annotations/2017\\\\542cd22c-ea80-4669-995b-6ac6a33823f7_3_ann.json', './BASIL/annotations/2017\\\\58f414e5-a122-49f5-819e-512d91069da5_1_ann.json', './BASIL/annotations/2017\\\\58f414e5-a122-49f5-819e-512d91069da5_2_ann.json', './BASIL/annotations/2017\\\\58f414e5-a122-49f5-819e-512d91069da5_3_ann.json', './BASIL/annotations/2017\\\\72fa9b13-4e59-4716-8df9-4c3580e7dddf_1_ann.json', './BASIL/annotations/2017\\\\72fa9b13-4e59-4716-8df9-4c3580e7dddf_2_ann.json', './BASIL/annotations/2017\\\\72fa9b13-4e59-4716-8df9-4c3580e7dddf_3_ann.json', './BASIL/annotations/2017\\\\84b3c118-50d2-45a5-a91f-7ed95b5d0143_1_ann.json', './BASIL/annotations/2017\\\\84b3c118-50d2-45a5-a91f-7ed95b5d0143_2_ann.json', './BASIL/annotations/2017\\\\84b3c118-50d2-45a5-a91f-7ed95b5d0143_3_ann.json', './BASIL/annotations/2017\\\\be026bd1-52b1-4789-bfd3-3632af17b054_1_ann.json', './BASIL/annotations/2017\\\\be026bd1-52b1-4789-bfd3-3632af17b054_2_ann.json', './BASIL/annotations/2017\\\\be026bd1-52b1-4789-bfd3-3632af17b054_3_ann.json', './BASIL/annotations/2017\\\\d16050b3-979f-4834-90db-b8823691b87e_1_ann.json', './BASIL/annotations/2017\\\\d16050b3-979f-4834-90db-b8823691b87e_2_ann.json', './BASIL/annotations/2017\\\\d16050b3-979f-4834-90db-b8823691b87e_3_ann.json', './BASIL/annotations/2017\\\\dd1e6e3b-f36c-4064-8ef9-940984e9afa2_1_ann.json', './BASIL/annotations/2017\\\\dd1e6e3b-f36c-4064-8ef9-940984e9afa2_2_ann.json', './BASIL/annotations/2017\\\\dd1e6e3b-f36c-4064-8ef9-940984e9afa2_3_ann.json', './BASIL/annotations/2017\\\\df6a55fb-dfe5-4362-89a6-8c040d648a70_1_ann.json', './BASIL/annotations/2017\\\\df6a55fb-dfe5-4362-89a6-8c040d648a70_2_ann.json', './BASIL/annotations/2017\\\\df6a55fb-dfe5-4362-89a6-8c040d648a70_3_ann.json', './BASIL/annotations/2018\\\\01c59743-7082-44fc-8414-3c04126f470f_1_ann.json', './BASIL/annotations/2018\\\\01c59743-7082-44fc-8414-3c04126f470f_2_ann.json', './BASIL/annotations/2018\\\\01c59743-7082-44fc-8414-3c04126f470f_3_ann.json', './BASIL/annotations/2018\\\\06ffda2d-1caf-45ba-99e2-268aac1bf0e1_1_ann.json', './BASIL/annotations/2018\\\\06ffda2d-1caf-45ba-99e2-268aac1bf0e1_2_ann.json', './BASIL/annotations/2018\\\\06ffda2d-1caf-45ba-99e2-268aac1bf0e1_3_ann.json', './BASIL/annotations/2018\\\\1ed4f378-b9d4-43b8-8d50-53d0cc063332_1_ann.json', './BASIL/annotations/2018\\\\1ed4f378-b9d4-43b8-8d50-53d0cc063332_2_ann.json', './BASIL/annotations/2018\\\\1ed4f378-b9d4-43b8-8d50-53d0cc063332_3_ann.json', './BASIL/annotations/2018\\\\1f99798f-2b60-4ecb-b5f4-4aa7991e8ace_1_ann.json', './BASIL/annotations/2018\\\\1f99798f-2b60-4ecb-b5f4-4aa7991e8ace_2_ann.json', './BASIL/annotations/2018\\\\1f99798f-2b60-4ecb-b5f4-4aa7991e8ace_3_ann.json', './BASIL/annotations/2018\\\\2a3fde8a-082a-4d8f-9567-f7e8366c0200_1_ann.json', './BASIL/annotations/2018\\\\2a3fde8a-082a-4d8f-9567-f7e8366c0200_2_ann.json', './BASIL/annotations/2018\\\\2a3fde8a-082a-4d8f-9567-f7e8366c0200_3_ann.json', './BASIL/annotations/2018\\\\87609973-bd58-42a5-96e2-ee5aa47433f5_1_ann.json', './BASIL/annotations/2018\\\\87609973-bd58-42a5-96e2-ee5aa47433f5_2_ann.json', './BASIL/annotations/2018\\\\87609973-bd58-42a5-96e2-ee5aa47433f5_3_ann.json', './BASIL/annotations/2018\\\\ad409798-ee94-4436-92c5-92669193be14_1_ann.json', './BASIL/annotations/2018\\\\ad409798-ee94-4436-92c5-92669193be14_2_ann.json', './BASIL/annotations/2018\\\\ad409798-ee94-4436-92c5-92669193be14_3_ann.json', './BASIL/annotations/2018\\\\c6a0e65c-4f8b-41de-8200-cd700f683c64_1_ann.json', './BASIL/annotations/2018\\\\c6a0e65c-4f8b-41de-8200-cd700f683c64_2_ann.json', './BASIL/annotations/2018\\\\c6a0e65c-4f8b-41de-8200-cd700f683c64_3_ann.json', './BASIL/annotations/2018\\\\eb17fa36-89f2-4d0b-8133-7bb4682228e1_1_ann.json', './BASIL/annotations/2018\\\\eb17fa36-89f2-4d0b-8133-7bb4682228e1_2_ann.json', './BASIL/annotations/2018\\\\eb17fa36-89f2-4d0b-8133-7bb4682228e1_3_ann.json', './BASIL/annotations/2018\\\\f688c56d-7fae-42ef-b7f7-7db207b58d27_1_ann.json', './BASIL/annotations/2018\\\\f688c56d-7fae-42ef-b7f7-7db207b58d27_2_ann.json', './BASIL/annotations/2018\\\\f688c56d-7fae-42ef-b7f7-7db207b58d27_3_ann.json', './BASIL/annotations/2019\\\\0d10341a-9dba-4374-a524-814c300d1611_1_ann.json', './BASIL/annotations/2019\\\\0d10341a-9dba-4374-a524-814c300d1611_2_ann.json', './BASIL/annotations/2019\\\\0d10341a-9dba-4374-a524-814c300d1611_3_ann.json', './BASIL/annotations/2019\\\\1e41e98b-9ac1-441d-b2c2-19d8f730c74a_1_ann.json', './BASIL/annotations/2019\\\\1e41e98b-9ac1-441d-b2c2-19d8f730c74a_2_ann.json', './BASIL/annotations/2019\\\\1e41e98b-9ac1-441d-b2c2-19d8f730c74a_3_ann.json', './BASIL/annotations/2019\\\\2f3e86b6-8443-47bd-9cd3-491c90a59fe9_1_ann.json', './BASIL/annotations/2019\\\\2f3e86b6-8443-47bd-9cd3-491c90a59fe9_2_ann.json', './BASIL/annotations/2019\\\\2f3e86b6-8443-47bd-9cd3-491c90a59fe9_3_ann.json', './BASIL/annotations/2019\\\\3ae35b16-7f7f-4a5e-9f24-5ce724106a73_1_ann.json', './BASIL/annotations/2019\\\\3ae35b16-7f7f-4a5e-9f24-5ce724106a73_2_ann.json', './BASIL/annotations/2019\\\\3ae35b16-7f7f-4a5e-9f24-5ce724106a73_3_ann.json', './BASIL/annotations/2019\\\\70c75d68-bf65-46a6-a822-15c23d77a275_1_ann.json', './BASIL/annotations/2019\\\\70c75d68-bf65-46a6-a822-15c23d77a275_2_ann.json', './BASIL/annotations/2019\\\\70c75d68-bf65-46a6-a822-15c23d77a275_3_ann.json', './BASIL/annotations/2019\\\\86e6e27d-1440-4879-8b13-0dd2d89f7281_1_ann.json', './BASIL/annotations/2019\\\\86e6e27d-1440-4879-8b13-0dd2d89f7281_2_ann.json', './BASIL/annotations/2019\\\\86e6e27d-1440-4879-8b13-0dd2d89f7281_3_ann.json', './BASIL/annotations/2019\\\\aab91277-8d56-4844-a581-45630f873f49_1_ann.json', './BASIL/annotations/2019\\\\aab91277-8d56-4844-a581-45630f873f49_2_ann.json', './BASIL/annotations/2019\\\\aab91277-8d56-4844-a581-45630f873f49_3_ann.json', './BASIL/annotations/2019\\\\b7021938-ff8d-42ea-adec-5704c0b65237_1_ann.json', './BASIL/annotations/2019\\\\b7021938-ff8d-42ea-adec-5704c0b65237_2_ann.json', './BASIL/annotations/2019\\\\b7021938-ff8d-42ea-adec-5704c0b65237_3_ann.json', './BASIL/annotations/2019\\\\c9e4d35f-aeae-462b-a8bf-e08d09a93b6e_1_ann.json', './BASIL/annotations/2019\\\\c9e4d35f-aeae-462b-a8bf-e08d09a93b6e_2_ann.json', './BASIL/annotations/2019\\\\c9e4d35f-aeae-462b-a8bf-e08d09a93b6e_3_ann.json', './BASIL/annotations/2019\\\\e71d149d-0426-43f0-87e8-8c611dad7205_1_ann.json', './BASIL/annotations/2019\\\\e71d149d-0426-43f0-87e8-8c611dad7205_2_ann.json', './BASIL/annotations/2019\\\\e71d149d-0426-43f0-87e8-8c611dad7205_3_ann.json']\n",
      "['./BASIL/articles/2010\\\\2b95d2cf-e979-4f9c-ae27-9a5370934f23_1.json', './BASIL/articles/2010\\\\2b95d2cf-e979-4f9c-ae27-9a5370934f23_2.json', './BASIL/articles/2010\\\\2b95d2cf-e979-4f9c-ae27-9a5370934f23_3.json', './BASIL/articles/2010\\\\38f7cbb7-5d6a-4c89-bcbd-8e164144172a_1.json', './BASIL/articles/2010\\\\38f7cbb7-5d6a-4c89-bcbd-8e164144172a_2.json', './BASIL/articles/2010\\\\38f7cbb7-5d6a-4c89-bcbd-8e164144172a_3.json', './BASIL/articles/2010\\\\45bd61bc-c356-4450-9e3a-cbfc862b09fd_1.json', './BASIL/articles/2010\\\\45bd61bc-c356-4450-9e3a-cbfc862b09fd_2.json', './BASIL/articles/2010\\\\45bd61bc-c356-4450-9e3a-cbfc862b09fd_3.json', './BASIL/articles/2010\\\\6b541575-99b1-40d2-8730-9bb868ee38ed_1.json', './BASIL/articles/2010\\\\6b541575-99b1-40d2-8730-9bb868ee38ed_2.json', './BASIL/articles/2010\\\\6b541575-99b1-40d2-8730-9bb868ee38ed_3.json', './BASIL/articles/2010\\\\6f95dcb9-e960-45ac-8c0e-91b85724c909_1.json', './BASIL/articles/2010\\\\6f95dcb9-e960-45ac-8c0e-91b85724c909_2.json', './BASIL/articles/2010\\\\6f95dcb9-e960-45ac-8c0e-91b85724c909_3.json', './BASIL/articles/2010\\\\74708dbf-5dfc-4c66-8419-d7dbc00e4a06_1.json', './BASIL/articles/2010\\\\74708dbf-5dfc-4c66-8419-d7dbc00e4a06_2.json', './BASIL/articles/2010\\\\74708dbf-5dfc-4c66-8419-d7dbc00e4a06_3.json', './BASIL/articles/2010\\\\85475456-f38e-4c30-895d-ca2c819c6af1_1.json', './BASIL/articles/2010\\\\85475456-f38e-4c30-895d-ca2c819c6af1_2.json', './BASIL/articles/2010\\\\85475456-f38e-4c30-895d-ca2c819c6af1_3.json', './BASIL/articles/2010\\\\97b1305c-13ca-4b74-a56a-f459bd79dfaf_1.json', './BASIL/articles/2010\\\\97b1305c-13ca-4b74-a56a-f459bd79dfaf_2.json', './BASIL/articles/2010\\\\97b1305c-13ca-4b74-a56a-f459bd79dfaf_3.json', './BASIL/articles/2010\\\\ae243a95-b2c2-410c-9e2b-b083b4b8eb48_1.json', './BASIL/articles/2010\\\\ae243a95-b2c2-410c-9e2b-b083b4b8eb48_2.json', './BASIL/articles/2010\\\\ae243a95-b2c2-410c-9e2b-b083b4b8eb48_3.json', './BASIL/articles/2010\\\\df5fe55a-dfcb-4817-8631-830f47c21a72_1.json', './BASIL/articles/2010\\\\df5fe55a-dfcb-4817-8631-830f47c21a72_2.json', './BASIL/articles/2010\\\\df5fe55a-dfcb-4817-8631-830f47c21a72_3.json', './BASIL/articles/2011\\\\005a2961-0c2e-4575-8eec-770ba52a08e0_1.json', './BASIL/articles/2011\\\\005a2961-0c2e-4575-8eec-770ba52a08e0_2.json', './BASIL/articles/2011\\\\005a2961-0c2e-4575-8eec-770ba52a08e0_3.json', './BASIL/articles/2011\\\\0ffb34cd-c367-4d90-aca7-7fcac3ed8f3d_1.json', './BASIL/articles/2011\\\\0ffb34cd-c367-4d90-aca7-7fcac3ed8f3d_2.json', './BASIL/articles/2011\\\\0ffb34cd-c367-4d90-aca7-7fcac3ed8f3d_3.json', './BASIL/articles/2011\\\\2058ec60-5372-4f5f-83a3-da780be3a350_1.json', './BASIL/articles/2011\\\\2058ec60-5372-4f5f-83a3-da780be3a350_2.json', './BASIL/articles/2011\\\\2058ec60-5372-4f5f-83a3-da780be3a350_3.json', './BASIL/articles/2011\\\\2153fb3e-6b09-410c-bfea-d095c49a54ba_1.json', './BASIL/articles/2011\\\\2153fb3e-6b09-410c-bfea-d095c49a54ba_2.json', './BASIL/articles/2011\\\\2153fb3e-6b09-410c-bfea-d095c49a54ba_3.json', './BASIL/articles/2011\\\\3db93526-a344-4ea4-8772-3734d0cfdfb1_1.json', './BASIL/articles/2011\\\\3db93526-a344-4ea4-8772-3734d0cfdfb1_2.json', './BASIL/articles/2011\\\\3db93526-a344-4ea4-8772-3734d0cfdfb1_3.json', './BASIL/articles/2011\\\\550b80db-bdd5-442b-8f70-c8e9f3203a13_1.json', './BASIL/articles/2011\\\\550b80db-bdd5-442b-8f70-c8e9f3203a13_2.json', './BASIL/articles/2011\\\\550b80db-bdd5-442b-8f70-c8e9f3203a13_3.json', './BASIL/articles/2011\\\\576116e5-2b18-4d35-be73-36f5863c9468_1.json', './BASIL/articles/2011\\\\576116e5-2b18-4d35-be73-36f5863c9468_2.json', './BASIL/articles/2011\\\\576116e5-2b18-4d35-be73-36f5863c9468_3.json', './BASIL/articles/2011\\\\97566c74-e000-49fb-b091-e6ec6e179de0_1.json', './BASIL/articles/2011\\\\97566c74-e000-49fb-b091-e6ec6e179de0_2.json', './BASIL/articles/2011\\\\97566c74-e000-49fb-b091-e6ec6e179de0_3.json', './BASIL/articles/2011\\\\a28a0329-0887-42dc-bd3d-3bb4f8926757_1.json', './BASIL/articles/2011\\\\a28a0329-0887-42dc-bd3d-3bb4f8926757_2.json', './BASIL/articles/2011\\\\a28a0329-0887-42dc-bd3d-3bb4f8926757_3.json', './BASIL/articles/2011\\\\c21cb217-3e2c-49bd-884d-5c74a165ef10_1.json', './BASIL/articles/2011\\\\c21cb217-3e2c-49bd-884d-5c74a165ef10_2.json', './BASIL/articles/2011\\\\c21cb217-3e2c-49bd-884d-5c74a165ef10_3.json', './BASIL/articles/2012\\\\08bb9bee-c167-4c17-9c6d-4a1259231eb7_1.json', './BASIL/articles/2012\\\\08bb9bee-c167-4c17-9c6d-4a1259231eb7_2.json', './BASIL/articles/2012\\\\08bb9bee-c167-4c17-9c6d-4a1259231eb7_3.json', './BASIL/articles/2012\\\\29ffd053-7684-469b-a600-97000579bd01_1.json', './BASIL/articles/2012\\\\29ffd053-7684-469b-a600-97000579bd01_2.json', './BASIL/articles/2012\\\\29ffd053-7684-469b-a600-97000579bd01_3.json', './BASIL/articles/2012\\\\2ec04201-2016-4227-baf7-ba8289058203_1.json', './BASIL/articles/2012\\\\2ec04201-2016-4227-baf7-ba8289058203_2.json', './BASIL/articles/2012\\\\2ec04201-2016-4227-baf7-ba8289058203_3.json', './BASIL/articles/2012\\\\450755dd-30d3-478b-933e-917be5c384ba_1.json', './BASIL/articles/2012\\\\450755dd-30d3-478b-933e-917be5c384ba_2.json', './BASIL/articles/2012\\\\450755dd-30d3-478b-933e-917be5c384ba_3.json', './BASIL/articles/2012\\\\65cb14cb-2d27-41e5-a2be-6fd6314f4363_1.json', './BASIL/articles/2012\\\\65cb14cb-2d27-41e5-a2be-6fd6314f4363_2.json', './BASIL/articles/2012\\\\65cb14cb-2d27-41e5-a2be-6fd6314f4363_3.json', './BASIL/articles/2012\\\\8dc7ccfe-5cf0-482f-9101-a7c69881da4d_1.json', './BASIL/articles/2012\\\\8dc7ccfe-5cf0-482f-9101-a7c69881da4d_2.json', './BASIL/articles/2012\\\\8dc7ccfe-5cf0-482f-9101-a7c69881da4d_3.json', './BASIL/articles/2012\\\\b4dbeda7-a1f3-4711-ae77-db23809d1ed2_1.json', './BASIL/articles/2012\\\\b4dbeda7-a1f3-4711-ae77-db23809d1ed2_2.json', './BASIL/articles/2012\\\\b4dbeda7-a1f3-4711-ae77-db23809d1ed2_3.json', './BASIL/articles/2012\\\\b5eefefb-2a33-45de-abe1-f855c94165f4_1.json', './BASIL/articles/2012\\\\b5eefefb-2a33-45de-abe1-f855c94165f4_2.json', './BASIL/articles/2012\\\\b5eefefb-2a33-45de-abe1-f855c94165f4_3.json', './BASIL/articles/2012\\\\cad4bba5-cf97-45cb-8059-ebeb47dcec7a_1.json', './BASIL/articles/2012\\\\cad4bba5-cf97-45cb-8059-ebeb47dcec7a_2.json', './BASIL/articles/2012\\\\cad4bba5-cf97-45cb-8059-ebeb47dcec7a_3.json', './BASIL/articles/2012\\\\f11c2566-848a-4e29-b8c5-4de0a81114e4_1.json', './BASIL/articles/2012\\\\f11c2566-848a-4e29-b8c5-4de0a81114e4_2.json', './BASIL/articles/2012\\\\f11c2566-848a-4e29-b8c5-4de0a81114e4_3.json', './BASIL/articles/2013\\\\11c9f251-35c8-4452-b052-df9be61464c6_1.json', './BASIL/articles/2013\\\\11c9f251-35c8-4452-b052-df9be61464c6_2.json', './BASIL/articles/2013\\\\11c9f251-35c8-4452-b052-df9be61464c6_3.json', './BASIL/articles/2013\\\\1bb79cc1-5d69-4136-a23d-6dbd300cbf25_1.json', './BASIL/articles/2013\\\\1bb79cc1-5d69-4136-a23d-6dbd300cbf25_2.json', './BASIL/articles/2013\\\\1bb79cc1-5d69-4136-a23d-6dbd300cbf25_3.json', './BASIL/articles/2013\\\\526cabb7-02a3-4adb-8e90-ec781c40c498_1.json', './BASIL/articles/2013\\\\526cabb7-02a3-4adb-8e90-ec781c40c498_2.json', './BASIL/articles/2013\\\\526cabb7-02a3-4adb-8e90-ec781c40c498_3.json', './BASIL/articles/2013\\\\68748e7f-cf6e-4ac7-8504-454c0876880d_1.json', './BASIL/articles/2013\\\\68748e7f-cf6e-4ac7-8504-454c0876880d_2.json', './BASIL/articles/2013\\\\68748e7f-cf6e-4ac7-8504-454c0876880d_3.json', './BASIL/articles/2013\\\\70c744ad-e950-445c-8a7a-0782b0a7d20b_1.json', './BASIL/articles/2013\\\\70c744ad-e950-445c-8a7a-0782b0a7d20b_2.json', './BASIL/articles/2013\\\\70c744ad-e950-445c-8a7a-0782b0a7d20b_3.json', './BASIL/articles/2013\\\\84678e18-0b79-4570-9c9f-cb1cf88d968e_1.json', './BASIL/articles/2013\\\\84678e18-0b79-4570-9c9f-cb1cf88d968e_2.json', './BASIL/articles/2013\\\\84678e18-0b79-4570-9c9f-cb1cf88d968e_3.json', './BASIL/articles/2013\\\\9879bbc0-eab3-482f-bf6b-a4b519393986_1.json', './BASIL/articles/2013\\\\9879bbc0-eab3-482f-bf6b-a4b519393986_2.json', './BASIL/articles/2013\\\\9879bbc0-eab3-482f-bf6b-a4b519393986_3.json', './BASIL/articles/2013\\\\a4f1d515-d7d9-4319-b2e0-4d56e9d45554_1.json', './BASIL/articles/2013\\\\a4f1d515-d7d9-4319-b2e0-4d56e9d45554_2.json', './BASIL/articles/2013\\\\a4f1d515-d7d9-4319-b2e0-4d56e9d45554_3.json', './BASIL/articles/2013\\\\d3a1ce0a-fc48-4827-a278-8f0ce8c7a519_1.json', './BASIL/articles/2013\\\\d3a1ce0a-fc48-4827-a278-8f0ce8c7a519_2.json', './BASIL/articles/2013\\\\d3a1ce0a-fc48-4827-a278-8f0ce8c7a519_3.json', './BASIL/articles/2013\\\\f506aafc-8b43-427a-936e-bbd1ef33e076_1.json', './BASIL/articles/2013\\\\f506aafc-8b43-427a-936e-bbd1ef33e076_2.json', './BASIL/articles/2013\\\\f506aafc-8b43-427a-936e-bbd1ef33e076_3.json', './BASIL/articles/2014\\\\22b6e900-4826-4b09-a9f8-5d7afe46e78b_1.json', './BASIL/articles/2014\\\\22b6e900-4826-4b09-a9f8-5d7afe46e78b_2.json', './BASIL/articles/2014\\\\22b6e900-4826-4b09-a9f8-5d7afe46e78b_3.json', './BASIL/articles/2014\\\\33521e65-12da-4521-b132-7b606243b0e4_1.json', './BASIL/articles/2014\\\\33521e65-12da-4521-b132-7b606243b0e4_2.json', './BASIL/articles/2014\\\\33521e65-12da-4521-b132-7b606243b0e4_3.json', './BASIL/articles/2014\\\\58ed2376-35a0-453a-a08e-5cd87e3bdea5_1.json', './BASIL/articles/2014\\\\58ed2376-35a0-453a-a08e-5cd87e3bdea5_2.json', './BASIL/articles/2014\\\\58ed2376-35a0-453a-a08e-5cd87e3bdea5_3.json', './BASIL/articles/2014\\\\96b7046f-f584-422f-a626-6f86a26dfd8b_1.json', './BASIL/articles/2014\\\\96b7046f-f584-422f-a626-6f86a26dfd8b_2.json', './BASIL/articles/2014\\\\96b7046f-f584-422f-a626-6f86a26dfd8b_3.json', './BASIL/articles/2014\\\\b764f81f-6d08-4d7c-b1a8-8961bed0a455_1.json', './BASIL/articles/2014\\\\b764f81f-6d08-4d7c-b1a8-8961bed0a455_2.json', './BASIL/articles/2014\\\\b764f81f-6d08-4d7c-b1a8-8961bed0a455_3.json', './BASIL/articles/2014\\\\c99adbdd-eaf3-4844-9548-2642e80de4e2_1.json', './BASIL/articles/2014\\\\c99adbdd-eaf3-4844-9548-2642e80de4e2_2.json', './BASIL/articles/2014\\\\c99adbdd-eaf3-4844-9548-2642e80de4e2_3.json', './BASIL/articles/2014\\\\ccf19ab6-7878-4378-b99c-2b08cc21371f_1.json', './BASIL/articles/2014\\\\ccf19ab6-7878-4378-b99c-2b08cc21371f_2.json', './BASIL/articles/2014\\\\ccf19ab6-7878-4378-b99c-2b08cc21371f_3.json', './BASIL/articles/2014\\\\d1344998-0e7c-409e-aaad-df5be687fc94_1.json', './BASIL/articles/2014\\\\d1344998-0e7c-409e-aaad-df5be687fc94_2.json', './BASIL/articles/2014\\\\d1344998-0e7c-409e-aaad-df5be687fc94_3.json', './BASIL/articles/2014\\\\ed8c136f-8d44-4c83-ad05-0dcfc3a0c54a_1.json', './BASIL/articles/2014\\\\ed8c136f-8d44-4c83-ad05-0dcfc3a0c54a_2.json', './BASIL/articles/2014\\\\ed8c136f-8d44-4c83-ad05-0dcfc3a0c54a_3.json', './BASIL/articles/2014\\\\ee05c9b3-529c-4268-ad72-19bd34f7197e_1.json', './BASIL/articles/2014\\\\ee05c9b3-529c-4268-ad72-19bd34f7197e_2.json', './BASIL/articles/2014\\\\ee05c9b3-529c-4268-ad72-19bd34f7197e_3.json', './BASIL/articles/2015\\\\13792511-5142-449f-8d3e-d77d790f65ec_1.json', './BASIL/articles/2015\\\\13792511-5142-449f-8d3e-d77d790f65ec_2.json', './BASIL/articles/2015\\\\13792511-5142-449f-8d3e-d77d790f65ec_3.json', './BASIL/articles/2015\\\\2742e9c1-2943-496f-8b23-faf5332e1612_1.json', './BASIL/articles/2015\\\\2742e9c1-2943-496f-8b23-faf5332e1612_2.json', './BASIL/articles/2015\\\\2742e9c1-2943-496f-8b23-faf5332e1612_3.json', './BASIL/articles/2015\\\\2b9468af-4ab0-4f25-85f4-c3ef93d72006_1.json', './BASIL/articles/2015\\\\2b9468af-4ab0-4f25-85f4-c3ef93d72006_2.json', './BASIL/articles/2015\\\\2b9468af-4ab0-4f25-85f4-c3ef93d72006_3.json', './BASIL/articles/2015\\\\4f473faf-f928-4cfd-8bed-00578be9db9a_1.json', './BASIL/articles/2015\\\\4f473faf-f928-4cfd-8bed-00578be9db9a_2.json', './BASIL/articles/2015\\\\4f473faf-f928-4cfd-8bed-00578be9db9a_3.json', './BASIL/articles/2015\\\\6e502405-bc90-4416-a787-3122918aa648_1.json', './BASIL/articles/2015\\\\6e502405-bc90-4416-a787-3122918aa648_2.json', './BASIL/articles/2015\\\\6e502405-bc90-4416-a787-3122918aa648_3.json', './BASIL/articles/2015\\\\7f9c83f7-3efa-4c7a-adef-3ebdeda96042_1.json', './BASIL/articles/2015\\\\7f9c83f7-3efa-4c7a-adef-3ebdeda96042_2.json', './BASIL/articles/2015\\\\7f9c83f7-3efa-4c7a-adef-3ebdeda96042_3.json', './BASIL/articles/2015\\\\8dac6c12-b5ca-468c-a249-7e0ab42f6b52_1.json', './BASIL/articles/2015\\\\8dac6c12-b5ca-468c-a249-7e0ab42f6b52_2.json', './BASIL/articles/2015\\\\8dac6c12-b5ca-468c-a249-7e0ab42f6b52_3.json', './BASIL/articles/2015\\\\a4edca3f-931f-4785-8c3f-f3d8fa84cbec_1.json', './BASIL/articles/2015\\\\a4edca3f-931f-4785-8c3f-f3d8fa84cbec_2.json', './BASIL/articles/2015\\\\a4edca3f-931f-4785-8c3f-f3d8fa84cbec_3.json', './BASIL/articles/2015\\\\af4a3f41-eeb5-49fa-a276-e97c230b25f0_1.json', './BASIL/articles/2015\\\\af4a3f41-eeb5-49fa-a276-e97c230b25f0_2.json', './BASIL/articles/2015\\\\af4a3f41-eeb5-49fa-a276-e97c230b25f0_3.json', './BASIL/articles/2015\\\\c5534b7e-a373-4962-8345-3847bc41a636_1.json', './BASIL/articles/2015\\\\c5534b7e-a373-4962-8345-3847bc41a636_2.json', './BASIL/articles/2015\\\\c5534b7e-a373-4962-8345-3847bc41a636_3.json', './BASIL/articles/2016\\\\1b96a5db-8974-46d3-82d7-5dfef02f650e_1.json', './BASIL/articles/2016\\\\1b96a5db-8974-46d3-82d7-5dfef02f650e_2.json', './BASIL/articles/2016\\\\1b96a5db-8974-46d3-82d7-5dfef02f650e_3.json', './BASIL/articles/2016\\\\472158a1-4e39-4214-8397-904e66f2b4c5_1.json', './BASIL/articles/2016\\\\472158a1-4e39-4214-8397-904e66f2b4c5_2.json', './BASIL/articles/2016\\\\472158a1-4e39-4214-8397-904e66f2b4c5_3.json', './BASIL/articles/2016\\\\59f2f47c-5da0-4fbc-be6e-4f15d45d82e2_1.json', './BASIL/articles/2016\\\\59f2f47c-5da0-4fbc-be6e-4f15d45d82e2_2.json', './BASIL/articles/2016\\\\59f2f47c-5da0-4fbc-be6e-4f15d45d82e2_3.json', './BASIL/articles/2016\\\\76810849-0335-4ad3-9eaf-f0d9c5baceb6_1.json', './BASIL/articles/2016\\\\76810849-0335-4ad3-9eaf-f0d9c5baceb6_2.json', './BASIL/articles/2016\\\\76810849-0335-4ad3-9eaf-f0d9c5baceb6_3.json', './BASIL/articles/2016\\\\79bf99c6-6fca-4ce4-8ae1-8771de026142_1.json', './BASIL/articles/2016\\\\79bf99c6-6fca-4ce4-8ae1-8771de026142_2.json', './BASIL/articles/2016\\\\79bf99c6-6fca-4ce4-8ae1-8771de026142_3.json', './BASIL/articles/2016\\\\7a97de89-1433-46f7-bcc2-f80b041cb9a0_1.json', './BASIL/articles/2016\\\\7a97de89-1433-46f7-bcc2-f80b041cb9a0_2.json', './BASIL/articles/2016\\\\7a97de89-1433-46f7-bcc2-f80b041cb9a0_3.json', './BASIL/articles/2016\\\\8385a996-1afc-4778-a06d-7070a8f19e27_1.json', './BASIL/articles/2016\\\\8385a996-1afc-4778-a06d-7070a8f19e27_2.json', './BASIL/articles/2016\\\\8385a996-1afc-4778-a06d-7070a8f19e27_3.json', './BASIL/articles/2016\\\\8abec8d9-50a2-480e-969a-157f94954f4d_1.json', './BASIL/articles/2016\\\\8abec8d9-50a2-480e-969a-157f94954f4d_2.json', './BASIL/articles/2016\\\\8abec8d9-50a2-480e-969a-157f94954f4d_3.json', './BASIL/articles/2016\\\\d4a4bc34-e48b-4485-86b2-f1daf4d464dd_1.json', './BASIL/articles/2016\\\\d4a4bc34-e48b-4485-86b2-f1daf4d464dd_2.json', './BASIL/articles/2016\\\\d4a4bc34-e48b-4485-86b2-f1daf4d464dd_3.json', './BASIL/articles/2016\\\\eadabee7-3db9-43c4-a485-3e8b1882cd3c_1.json', './BASIL/articles/2016\\\\eadabee7-3db9-43c4-a485-3e8b1882cd3c_2.json', './BASIL/articles/2016\\\\eadabee7-3db9-43c4-a485-3e8b1882cd3c_3.json', './BASIL/articles/2017\\\\0c78e748-efbf-417c-a8c1-beeb6480147f_1.json', './BASIL/articles/2017\\\\0c78e748-efbf-417c-a8c1-beeb6480147f_2.json', './BASIL/articles/2017\\\\0c78e748-efbf-417c-a8c1-beeb6480147f_3.json', './BASIL/articles/2017\\\\47a209b0-fc26-4a0a-a1fe-e4310d1d2419_1.json', './BASIL/articles/2017\\\\47a209b0-fc26-4a0a-a1fe-e4310d1d2419_2.json', './BASIL/articles/2017\\\\47a209b0-fc26-4a0a-a1fe-e4310d1d2419_3.json', './BASIL/articles/2017\\\\542cd22c-ea80-4669-995b-6ac6a33823f7_1.json', './BASIL/articles/2017\\\\542cd22c-ea80-4669-995b-6ac6a33823f7_2.json', './BASIL/articles/2017\\\\542cd22c-ea80-4669-995b-6ac6a33823f7_3.json', './BASIL/articles/2017\\\\58f414e5-a122-49f5-819e-512d91069da5_1.json', './BASIL/articles/2017\\\\58f414e5-a122-49f5-819e-512d91069da5_2.json', './BASIL/articles/2017\\\\58f414e5-a122-49f5-819e-512d91069da5_3.json', './BASIL/articles/2017\\\\72fa9b13-4e59-4716-8df9-4c3580e7dddf_1.json', './BASIL/articles/2017\\\\72fa9b13-4e59-4716-8df9-4c3580e7dddf_2.json', './BASIL/articles/2017\\\\72fa9b13-4e59-4716-8df9-4c3580e7dddf_3.json', './BASIL/articles/2017\\\\84b3c118-50d2-45a5-a91f-7ed95b5d0143_1.json', './BASIL/articles/2017\\\\84b3c118-50d2-45a5-a91f-7ed95b5d0143_2.json', './BASIL/articles/2017\\\\84b3c118-50d2-45a5-a91f-7ed95b5d0143_3.json', './BASIL/articles/2017\\\\be026bd1-52b1-4789-bfd3-3632af17b054_1.json', './BASIL/articles/2017\\\\be026bd1-52b1-4789-bfd3-3632af17b054_2.json', './BASIL/articles/2017\\\\be026bd1-52b1-4789-bfd3-3632af17b054_3.json', './BASIL/articles/2017\\\\d16050b3-979f-4834-90db-b8823691b87e_1.json', './BASIL/articles/2017\\\\d16050b3-979f-4834-90db-b8823691b87e_2.json', './BASIL/articles/2017\\\\d16050b3-979f-4834-90db-b8823691b87e_3.json', './BASIL/articles/2017\\\\dd1e6e3b-f36c-4064-8ef9-940984e9afa2_1.json', './BASIL/articles/2017\\\\dd1e6e3b-f36c-4064-8ef9-940984e9afa2_2.json', './BASIL/articles/2017\\\\dd1e6e3b-f36c-4064-8ef9-940984e9afa2_3.json', './BASIL/articles/2017\\\\df6a55fb-dfe5-4362-89a6-8c040d648a70_1.json', './BASIL/articles/2017\\\\df6a55fb-dfe5-4362-89a6-8c040d648a70_2.json', './BASIL/articles/2017\\\\df6a55fb-dfe5-4362-89a6-8c040d648a70_3.json', './BASIL/articles/2018\\\\01c59743-7082-44fc-8414-3c04126f470f_1.json', './BASIL/articles/2018\\\\01c59743-7082-44fc-8414-3c04126f470f_2.json', './BASIL/articles/2018\\\\01c59743-7082-44fc-8414-3c04126f470f_3.json', './BASIL/articles/2018\\\\06ffda2d-1caf-45ba-99e2-268aac1bf0e1_1.json', './BASIL/articles/2018\\\\06ffda2d-1caf-45ba-99e2-268aac1bf0e1_2.json', './BASIL/articles/2018\\\\06ffda2d-1caf-45ba-99e2-268aac1bf0e1_3.json', './BASIL/articles/2018\\\\1ed4f378-b9d4-43b8-8d50-53d0cc063332_1.json', './BASIL/articles/2018\\\\1ed4f378-b9d4-43b8-8d50-53d0cc063332_2.json', './BASIL/articles/2018\\\\1ed4f378-b9d4-43b8-8d50-53d0cc063332_3.json', './BASIL/articles/2018\\\\1f99798f-2b60-4ecb-b5f4-4aa7991e8ace_1.json', './BASIL/articles/2018\\\\1f99798f-2b60-4ecb-b5f4-4aa7991e8ace_2.json', './BASIL/articles/2018\\\\1f99798f-2b60-4ecb-b5f4-4aa7991e8ace_3.json', './BASIL/articles/2018\\\\2a3fde8a-082a-4d8f-9567-f7e8366c0200_1.json', './BASIL/articles/2018\\\\2a3fde8a-082a-4d8f-9567-f7e8366c0200_2.json', './BASIL/articles/2018\\\\2a3fde8a-082a-4d8f-9567-f7e8366c0200_3.json', './BASIL/articles/2018\\\\87609973-bd58-42a5-96e2-ee5aa47433f5_1.json', './BASIL/articles/2018\\\\87609973-bd58-42a5-96e2-ee5aa47433f5_2.json', './BASIL/articles/2018\\\\87609973-bd58-42a5-96e2-ee5aa47433f5_3.json', './BASIL/articles/2018\\\\ad409798-ee94-4436-92c5-92669193be14_1.json', './BASIL/articles/2018\\\\ad409798-ee94-4436-92c5-92669193be14_2.json', './BASIL/articles/2018\\\\ad409798-ee94-4436-92c5-92669193be14_3.json', './BASIL/articles/2018\\\\c6a0e65c-4f8b-41de-8200-cd700f683c64_1.json', './BASIL/articles/2018\\\\c6a0e65c-4f8b-41de-8200-cd700f683c64_2.json', './BASIL/articles/2018\\\\c6a0e65c-4f8b-41de-8200-cd700f683c64_3.json', './BASIL/articles/2018\\\\eb17fa36-89f2-4d0b-8133-7bb4682228e1_1.json', './BASIL/articles/2018\\\\eb17fa36-89f2-4d0b-8133-7bb4682228e1_2.json', './BASIL/articles/2018\\\\eb17fa36-89f2-4d0b-8133-7bb4682228e1_3.json', './BASIL/articles/2018\\\\f688c56d-7fae-42ef-b7f7-7db207b58d27_1.json', './BASIL/articles/2018\\\\f688c56d-7fae-42ef-b7f7-7db207b58d27_2.json', './BASIL/articles/2018\\\\f688c56d-7fae-42ef-b7f7-7db207b58d27_3.json', './BASIL/articles/2019\\\\0d10341a-9dba-4374-a524-814c300d1611_1.json', './BASIL/articles/2019\\\\0d10341a-9dba-4374-a524-814c300d1611_2.json', './BASIL/articles/2019\\\\0d10341a-9dba-4374-a524-814c300d1611_3.json', './BASIL/articles/2019\\\\1e41e98b-9ac1-441d-b2c2-19d8f730c74a_1.json', './BASIL/articles/2019\\\\1e41e98b-9ac1-441d-b2c2-19d8f730c74a_2.json', './BASIL/articles/2019\\\\1e41e98b-9ac1-441d-b2c2-19d8f730c74a_3.json', './BASIL/articles/2019\\\\2f3e86b6-8443-47bd-9cd3-491c90a59fe9_1.json', './BASIL/articles/2019\\\\2f3e86b6-8443-47bd-9cd3-491c90a59fe9_2.json', './BASIL/articles/2019\\\\2f3e86b6-8443-47bd-9cd3-491c90a59fe9_3.json', './BASIL/articles/2019\\\\3ae35b16-7f7f-4a5e-9f24-5ce724106a73_1.json', './BASIL/articles/2019\\\\3ae35b16-7f7f-4a5e-9f24-5ce724106a73_2.json', './BASIL/articles/2019\\\\3ae35b16-7f7f-4a5e-9f24-5ce724106a73_3.json', './BASIL/articles/2019\\\\70c75d68-bf65-46a6-a822-15c23d77a275_1.json', './BASIL/articles/2019\\\\70c75d68-bf65-46a6-a822-15c23d77a275_2.json', './BASIL/articles/2019\\\\70c75d68-bf65-46a6-a822-15c23d77a275_3.json', './BASIL/articles/2019\\\\86e6e27d-1440-4879-8b13-0dd2d89f7281_1.json', './BASIL/articles/2019\\\\86e6e27d-1440-4879-8b13-0dd2d89f7281_2.json', './BASIL/articles/2019\\\\86e6e27d-1440-4879-8b13-0dd2d89f7281_3.json', './BASIL/articles/2019\\\\aab91277-8d56-4844-a581-45630f873f49_1.json', './BASIL/articles/2019\\\\aab91277-8d56-4844-a581-45630f873f49_2.json', './BASIL/articles/2019\\\\aab91277-8d56-4844-a581-45630f873f49_3.json', './BASIL/articles/2019\\\\b7021938-ff8d-42ea-adec-5704c0b65237_1.json', './BASIL/articles/2019\\\\b7021938-ff8d-42ea-adec-5704c0b65237_2.json', './BASIL/articles/2019\\\\b7021938-ff8d-42ea-adec-5704c0b65237_3.json', './BASIL/articles/2019\\\\c9e4d35f-aeae-462b-a8bf-e08d09a93b6e_1.json', './BASIL/articles/2019\\\\c9e4d35f-aeae-462b-a8bf-e08d09a93b6e_2.json', './BASIL/articles/2019\\\\c9e4d35f-aeae-462b-a8bf-e08d09a93b6e_3.json', './BASIL/articles/2019\\\\e71d149d-0426-43f0-87e8-8c611dad7205_1.json', './BASIL/articles/2019\\\\e71d149d-0426-43f0-87e8-8c611dad7205_2.json', './BASIL/articles/2019\\\\e71d149d-0426-43f0-87e8-8c611dad7205_3.json']\n"
     ]
    }
   ],
   "source": [
    "annotations_path = sorted(annotations_path)\n",
    "articles_path = sorted(articles_path)\n",
    "\n",
    "print(annotations_path)\n",
    "print(articles_path)\n",
    "annotations = []\n",
    "articles = []\n",
    "for path in sorted(annotations_path):\n",
    "  with open(path, 'r') as fp:\n",
    "    annotations.append(json.load(fp))\n",
    "\n",
    "for path in sorted(articles_path):\n",
    "  with open(path, 'r') as fp:\n",
    "    articles.append(json.load(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = []\n",
    "all_labels = []\n",
    "\n",
    "for i in range(len(articles)):\n",
    "    paragraphs = articles[i][\"body-paragraphs\"]\n",
    "    sentences = [sent for para in paragraphs for sent in para]\n",
    "    annotats = annotations[i][\"phrase-level-annotations\"]\n",
    "    labels = [0 for _ in range(len(sentences))]\n",
    "    for annot in annotats:\n",
    "        if annot[\"id\"][0] == 'p':\n",
    "            id = int(annot[\"id\"][1:])\n",
    "            polarity = annot['polarity']\n",
    "            if polarity == 'neg':\n",
    "                labels[id] = 1\n",
    "            elif polarity == 'pos':\n",
    "                labels[id] = 2\n",
    "    all_sentences.append(sentences)\n",
    "    all_labels.append(labels)\n",
    "\n",
    "sentence_data = [sent for sublist in all_sentences for sent in sublist]\n",
    "label_data = [label for sublist in all_labels for label in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(sentence_data)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_split = int(len(indices) * 0.7)\n",
    "val_split = int(len(indices) * 0.15)\n",
    "\n",
    "train_idx = indices[:train_split]\n",
    "val_idx = indices[train_split : train_split+val_split]\n",
    "test_idx = indices[train_split+val_split : ]\n",
    "\n",
    "\n",
    "train_sentences = [sentence_data[i] for i in train_idx]\n",
    "train_labels = [label_data[i] for i in train_idx]\n",
    "val_sentences = [sentence_data[i] for i in val_idx]\n",
    "val_labels = [label_data[i] for i in val_idx]\n",
    "test_sentences = [sentence_data[i] for i in test_idx]\n",
    "test_labels = [label_data[i] for i in test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\ProgramFiles\\anaconda3\\envs\\eecs487_project\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "class BasilDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len     \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_basil_dataset = BasilDataset(train_sentences, train_labels, tokenizer, 128)\n",
    "val_basil_dataset = BasilDataset(val_sentences, val_labels, tokenizer, 128)\n",
    "test_basil_dataset = BasilDataset(test_sentences, test_labels, tokenizer, 128)\n",
    "\n",
    "train_basil_loader = DataLoader(train_basil_dataset, batch_size=16, shuffle=True)\n",
    "val_basil_loader = DataLoader(val_basil_dataset, batch_size=16, shuffle=False)\n",
    "test_basil_loader = DataLoader(test_basil_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\ProgramFiles\\anaconda3\\envs\\eecs487_project\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_out = 3\n",
    "model_basil = BertClassifier(num_out)\n",
    "\n",
    "optimizer = AdamW(model_basil.parameters(), lr=5e-6)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "model_basil.to(device)\n",
    "loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [00:32<00:00, 10.82it/s]\n",
      "100%|██████████| 75/75 [00:02<00:00, 28.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1, Train Loss:  0.039, Train Accuracy:  0.778, Val Loss:  0.035, Val Accuracy:  0.811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [00:30<00:00, 11.38it/s]\n",
      "100%|██████████| 75/75 [00:02<00:00, 29.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2, Train Loss:  0.034, Train Accuracy:  0.801, Val Loss:  0.032, Val Accuracy:  0.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [00:30<00:00, 11.41it/s]\n",
      "100%|██████████| 75/75 [00:02<00:00, 29.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3, Train Loss:  0.030, Train Accuracy:  0.824, Val Loss:  0.031, Val Accuracy:  0.824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [00:30<00:00, 11.41it/s]\n",
      "100%|██████████| 75/75 [00:02<00:00, 29.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4, Train Loss:  0.025, Train Accuracy:  0.853, Val Loss:  0.031, Val Accuracy:  0.835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [00:31<00:00, 11.20it/s]\n",
      "100%|██████████| 75/75 [00:02<00:00, 28.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5, Train Loss:  0.019, Train Accuracy:  0.888, Val Loss:  0.034, Val Accuracy:  0.810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_basil.train()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "\n",
    "    for inputs in tqdm(train_basil_loader):\n",
    "        input_ids = inputs[\"input_ids\"].to(device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "        labels = inputs[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model_basil(input_ids, attention_mask)\n",
    "        loss = loss_fn(output, labels)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc += (output.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    total_dev_loss = 0\n",
    "    total_dev_acc = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for inputs in tqdm(val_basil_loader):\n",
    "            input_ids = inputs[\"input_ids\"].to(device)\n",
    "            attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "            labels = inputs[\"label\"].to(device)\n",
    "\n",
    "            output = model_basil(input_ids, attention_mask)\n",
    "            loss = loss_fn(output, labels)\n",
    "\n",
    "            total_dev_loss += loss.item()\n",
    "            total_dev_acc += (output.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "    print(f'Epochs: {epoch + 1}, Train Loss: {total_loss / len(train_basil_dataset): .3f}, Train Accuracy: {total_acc / len(train_basil_dataset): .3f}, Val Loss: {total_dev_loss / len(val_basil_dataset): .3f}, Val Accuracy: {total_dev_acc / len(val_basil_dataset): .3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 30.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_test_acc = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_basil.eval()\n",
    "    for inputs in tqdm(test_basil_loader):\n",
    "        input_ids = inputs[\"input_ids\"].to(device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "        labels = inputs[\"label\"].to(device)\n",
    "\n",
    "        output = model_basil(input_ids, attention_mask)\n",
    "        \n",
    "        total_test_acc += (output.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {total_test_acc / len(test_basil_dataset): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  1109,  2793,  7853,  1521,  1118,  1535,  1517,  1254,  1454,\n",
      "         22911,   117,  1114,  1317,  3756,  1104,  6438,  1149, 22224,  1116,\n",
      "          1105, 27447,  4658,   119,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1124,  1209,  1256,  1129,  1737,  1176,   170, 20365,  1272,\n",
      "          1195,  1274,   787,   189,  4392,  1106,  1129, 16921,  1176,  1195,\n",
      "          1198,  1767,   117,  1105,  1122,  1431,  1136,  3333,   119,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]])\n",
      "tensor([[101,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 102,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [101,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0, 102,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0]])\n"
     ]
    }
   ],
   "source": [
    "import captum\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "sentences = [\"The recent protests led by women once again turned chaotic, with several reports of emotional outbursts and irrational behavior.\", \"He will even be considered like a traitor because we don\\u2019t accept to be offended like we just heard, and it should not happen.\"]\n",
    "\n",
    "inputs = tokenizer(sentences, padding='max_length', max_length=128, truncation=True, return_tensors=\"pt\")\n",
    "input_ids = inputs['input_ids']\n",
    "attention_masks = inputs['attention_mask']\n",
    "\n",
    "print(input_ids)\n",
    "baseline = torch.zeros_like(input_ids)\n",
    "baseline[input_ids == 101] = 101\n",
    "baseline[input_ids == 102] = 102\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = model_basil\n",
    "\n",
    "lig = captum.attr.LayerIntegratedGradients(net, net.bert.embeddings)\n",
    "\n",
    "target = torch.tensor([1, 1])\n",
    "\n",
    "net = net.to('cpu')\n",
    "attributions, delta = lig.attribute(inputs=(input_ids, attention_masks), target = target, baselines = (baseline, attention_masks), n_steps=50, return_convergence_delta=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128, 768])\n"
     ]
    }
   ],
   "source": [
    "print(attributions.shape)\n",
    "def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions\n",
    "\n",
    "attributions_sum = summarize_attributions(attributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7248,  0.8876, -2.7444],\n",
      "        [-0.7599,  2.1960, -2.0471]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "logits = net(input_ids, attention_masks)\n",
    "predicted_labels = torch.argmax(logits, dim=1)\n",
    "print(logits)\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>None</b></text></td><td><text style=\"padding-right:2em\"><b>1 (0.89)</b></text></td><td><text style=\"padding-right:2em\"><b>None</b></text></td><td><text style=\"padding-right:2em\"><b>0.61</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> The                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> recent                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> protests                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> led                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> women                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> once                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> again                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> turned                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> chaotic                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> several                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> reports                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> emotional                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> out                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##burst                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> irrational                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> behavior                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>None</b></text></td><td><text style=\"padding-right:2em\"><b>1 (2.20)</b></text></td><td><text style=\"padding-right:2em\"><b>None</b></text></td><td><text style=\"padding-right:2em\"><b>1.50</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> He                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> will                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> even                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> be                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> considered                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> like                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 68%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> traitor                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> because                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> we                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> don                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ’                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> t                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> accept                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> be                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> offended                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> like                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> we                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> just                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> heard                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> should                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> not                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> happen                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>None</b></text></td><td><text style=\"padding-right:2em\"><b>1 (0.89)</b></text></td><td><text style=\"padding-right:2em\"><b>None</b></text></td><td><text style=\"padding-right:2em\"><b>0.61</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> The                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> recent                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> protests                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> led                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> women                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> once                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> again                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> turned                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> chaotic                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> several                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> reports                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> emotional                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> out                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##burst                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> irrational                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> behavior                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>None</b></text></td><td><text style=\"padding-right:2em\"><b>1 (2.20)</b></text></td><td><text style=\"padding-right:2em\"><b>None</b></text></td><td><text style=\"padding-right:2em\"><b>1.50</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> He                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> will                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> even                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> be                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> considered                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> like                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 68%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> traitor                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> because                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> we                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> don                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ’                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> t                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> accept                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> be                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> offended                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> like                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> we                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> just                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> heard                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> should                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> not                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> happen                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from captum.attr import visualization as viz\n",
    "\n",
    "viz_records = []\n",
    "for i in range(len(sentences)):\n",
    "    # Get predicted label for current input sentence\n",
    "    logits = net(input_ids[i].unsqueeze(0), attention_masks[i].unsqueeze(0))\n",
    "    predicted_label = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    # Normalize attributions for current input sentence\n",
    "    normalized_attributions = attributions[i]\n",
    "    raw_inputs = tokenizer.convert_ids_to_tokens(input_ids[i])\n",
    "    raw_inputs = [t for t in raw_inputs if t != '[PAD]']\n",
    "    \n",
    "    # Create VisualizationDataRecord object\n",
    "    record = viz.VisualizationDataRecord(\n",
    "        word_attributions=attributions_sum[i].tolist(),\n",
    "        pred_class=predicted_labels[i].item(),\n",
    "        pred_prob=logits[0][predicted_label].item(),\n",
    "        true_class=None,\n",
    "        attr_class=None,\n",
    "        raw_input_ids=raw_inputs,\n",
    "        attr_score=torch.sum(attributions_sum[i]),\n",
    "        convergence_score=torch.sum(torch.abs(attributions_sum[i])).tolist()\n",
    "    )\n",
    "    viz_records.append(record)\n",
    "\n",
    "# Create visualization\n",
    "viz.visualize_text(viz_records)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eecs487_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
